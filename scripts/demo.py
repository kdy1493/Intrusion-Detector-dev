import cv2
import time
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from threading import Thread
from typing import List
import re
import warnings
import sys
# -----------------------------------------------------------------------------
# Configuration â€“ tweak here if needed
# -----------------------------------------------------------------------------
TEMPERATURE = 0.1
TOP_P       = 0.15
DURATION_SEC = 5        # default recording length
FPS          = 20

# PROMPT ðŸ‘‰ oneâ€‘line action/state only, no appearance/background
PROMPT = (
    "Video: <image><image><image><image><image><image><image><image>\n"
    "Return **one concise English sentence** that describes ONLY the subject's action or state change. "
    "Do NOT mention appearance, colour, clothing, background, objects, or physical attributes."
)

# DAM script location â€” resolve project root one level above this file
PROJECT_ROOT = Path(__file__).resolve().parent.parent  # .. (repo root)
DAM_SCRIPT   = PROJECT_ROOT / "src" / "dam_video_with_sam2.py"
if not DAM_SCRIPT.exists():
    raise FileNotFoundError(f"DAM script not found at: {DAM_SCRIPT}")

# I/O paths (under project root)
CAPTURE_DIR = PROJECT_ROOT / "captures"
CAPTURE_DIR.mkdir(exist_ok=True)
LOG_FILE    = PROJECT_ROOT / "action_log.txt"


# -----------------------------------------------------------------------------
# Helper: run DAM+SAMâ€‘2 and return oneâ€‘line description (progress lines filtered)
# -----------------------------------------------------------------------------

def _extract_description(raw: str) -> str:
    """Strip tqdm/progress logs & warnings â†’ return the Description line or last clean line."""
    desc = ""
    for line in raw.splitlines():
        if line.startswith("Description:"):
            desc = line.split("Description:", 1)[1].strip()
    if desc:
        return desc

    # fallback â€“ pick the last nonâ€‘empty line that is not a progress bar/warning
    clean_lines = [l for l in raw.splitlines() if l.strip() and not re.search(r"frame loading|propagate in video|Loading checkpoint|UserWarning", l)]
    return clean_lines[-1].strip() if clean_lines else raw.strip()


def describe_video(video_path: Path, box_norm: List[float]) -> str:
    """Run the DAM+SAMâ€‘2 CLI with fixed prompt â†’ return oneâ€‘line description."""
    cmd = [
        sys.executable, str(DAM_SCRIPT),
        "--video_file", str(video_path),
        "--box", str(box_norm),
        "--normalized_coords",
        "--use_box",
        "--no_stream",
        "--temperature", str(TEMPERATURE),
        "--top_p",      str(TOP_P),
        "--query", PROMPT,
    ]

    result = subprocess.run(cmd, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode != 0:
        print("[DAM stderr] â†“â†“â†“")
        print(result.stderr)
        raise RuntimeError(f"DAM exited {result.returncode}")

    return _extract_description(result.stdout or result.stderr)

# -----------------------------------------------------------------------------
# ROI selection on first frame â€“ returns normalised box [x1,y1,x2,y2]
# -----------------------------------------------------------------------------

def select_roi(video_path: Path) -> List[float]:
    cap = cv2.VideoCapture(str(video_path))
    ok, frame = cap.read(); cap.release()
    if not ok:
        raise RuntimeError("Cannot read first frame.")

    x, y, w, h = cv2.selectROI("Select ROI (Enter/Space = OK, ESC = Cancel)", frame, False, False)
    cv2.destroyWindow("Select ROI (Enter/Space = OK, ESC = Cancel)")

    if w == 0 or h == 0:  # user cancelled â€“ use full frame
        return [0.0, 0.0, 1.0, 1.0]

    h_img, w_img = frame.shape[:2]
    box_norm = [x / w_img, y / h_img, (x + w) / w_img, (y + h) / h_img]
    return [round(v, 4) for v in box_norm]

# -----------------------------------------------------------------------------
# Logging helper â€“ append to action_log.txt in twoâ€‘column TSV format
# -----------------------------------------------------------------------------

def append_log(start_dt: datetime, end_dt: datetime, description: str) -> None:
    """Append a row: <YYYYâ€‘MMâ€‘DDâ€‘HHMMSS~HHMMSS> \t <description>"""
    time_range = f"{start_dt.strftime('%Y-%m-%d-%H%M%S')}~{end_dt.strftime('%H%M%S')}"
    with LOG_FILE.open("a", encoding="utf8") as f:
        f.write(f"{time_range}\t{description}\n")

# -----------------------------------------------------------------------------
# Record clip â†’ run DAM in background thread, then log result
# -----------------------------------------------------------------------------

def record_and_describe(cap: cv2.VideoCapture, duration: int = DURATION_SEC, fps: int = FPS):
    w  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    h  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    start_dt = datetime.now()
    vid_path = CAPTURE_DIR / f"video_{start_dt.strftime('%Y%m%d_%H%M%S')}.mp4"

    vw = cv2.VideoWriter(str(vid_path),
                         cv2.VideoWriter_fourcc(*"mp4v"),
                         fps, (w, h))
    if not vw.isOpened():
        warnings.warn("VideoWriter failed to open â€“ check codec/FourCC")
        return

    t0 = time.time()
    while time.time() - t0 < duration:
        ok, frame = cap.read()
        if not ok:
            break
        vw.write(frame)

    vw.release()
    print(f"[INFO] recording saved: {vid_path}")
    end_dt = start_dt + timedelta(seconds=duration)

    # run ROI selection + DAM asynchronously
    def _run():
        try:
            box_norm = select_roi(vid_path)
            desc     = describe_video(vid_path, box_norm)
            print(f"[DAM] {desc}")
            append_log(start_dt, end_dt, desc)
        except Exception as e:
            print("[ERR] DAM inference failed:", e)

    Thread(target=_run, daemon=True).start()

# -----------------------------------------------------------------------------
# Main camera loop â€“ press 's' to record, 'q' to quit
# -----------------------------------------------------------------------------

def main():
    # ì¹´ë©”ë¼ 1 ì‚¬ìš© (ë” ì•ˆì •ì )
    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
    if not cap.isOpened():
        print("ì¹´ë©”ë¼ 1ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ 0ì„ ì‹œë„í•©ë‹ˆë‹¤...")
        cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
        if not cap.isOpened():
            print("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
    
    # ì¹´ë©”ë¼ ì„¤ì • ìµœì í™”
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    cap.set(cv2.CAP_PROP_FPS, 30)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ í¬ê¸° ì¤„ì—¬ì„œ ì§€ì—° ê°ì†Œ
    
    print("s: record 5 seconds | q: quit")
    while True:
        ret, frame = cap.read()
        if not ret:
            print("í”„ë ˆìž„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        cv2.imshow("Camera", frame)
        key = cv2.waitKey(1) & 0xFF

        if key == ord('s'):
            print("[INFO] recording 5 seconds â€¦")
            Thread(target=record_and_describe, args=(cap,), daemon=True).start()

        elif key == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# -----------------------------------------------------------------------------

if __name__ == "__main__":
    # í™˜ê²½ ì²´í¬ (ì„ íƒ) - ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¹€
    try:
        import sam2, torch
        # if not hasattr(sam2, "_C"):
        #     warnings.warn("âš  SAM2 C-extension not found â€“ using Dummy predictor (qualityâ†“)")

        if not torch.cuda.is_available():
            warnings.warn("âš  CUDA not available â€“ inference will run on CPU (slow)")
    except ImportError:
        warnings.warn("sam2 or torch not importable â€“ please check installation")

    main()
